{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team_Microsoft.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN97HscknHxqC5/B7kShWHx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KVVisDon/Data-Mining-Project/blob/main/code/Team_Microsoft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EhAq-1bHL7f"
      },
      "source": [
        "# Team Microsoft\n",
        "\n",
        "## 1: Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqybCM22GNoK"
      },
      "source": [
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import sklearn\n",
        "import csv,json\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import collections  as mc\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS as stpw\n",
        "\n",
        "#sns.set_style(\"white\")\n",
        "#%load_ext autoreload\n",
        "#%autoreload 2\n",
        "#from sklearn import datasets\n",
        "\n",
        "\n",
        "#%load_ext autoreload\n",
        "#%autoreload 2"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdfvQrfuHugA"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/KVVisDon/Data-Mining-Project/main/data/training_data.csv\")\n",
        "df\n",
        "\n",
        "df_test = pd.read_csv(\"https://raw.githubusercontent.com/KVVisDon/Data-Mining-Project/main/data/test_data.csv\")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgJQp-GcLSFu"
      },
      "source": [
        "## 1.2: Base rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-NpB7-yKVNl",
        "outputId": "66368b51-7f89-4abd-d2b8-b04832197a0a"
      },
      "source": [
        "br = df.target.value_counts().max()/df.target.value_counts().sum()\n",
        "number_per_class = df.target.value_counts()\n",
        "print(number_per_class)\n",
        "print(\"Base rate is\",str(round(br,2)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    3701\n",
            "1    2770\n",
            "Name: target, dtype: int64\n",
            "Base rate is 0.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6PgvxmCMBVj"
      },
      "source": [
        "# 2: Cleaning\n",
        "###Basic : first we defined a tokenzation function, and removed duplicates based on subset ['text','keyword']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "yoxNFpTuMMbN",
        "outputId": "ba7fa6fe-e850-420b-eb00-cdfaea00d2e8"
      },
      "source": [
        "#Tokenization function : lower-case, lemmatizing, remove \"stop words\", remove \"punctuations\"\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "punctuations = string.punctuation\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "def spa_tok(message):\n",
        "  mytokens = sp(message)\n",
        "\n",
        "# Lemmatize each token and convert each token into lowercase\n",
        "  mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "# Remove stop words and punctuation\n",
        "  mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "# Remove hashtags, @\n",
        "\n",
        "  mytokens = [ word.replace('@','').replace('#', '') for word in mytokens ]\n",
        "\n",
        "  mytokens = [ word.replace('rt @', '').replace('rt', '') for word in mytokens ]\n",
        "     \n",
        "  mytokens = [ word for word in mytokens if word not in [\"\"] ]\n",
        "\n",
        "  mytokens = [ word for word in mytokens if word not in [\"\"] ]\n",
        "\n",
        "  return mytokens\n",
        "\n",
        "#remove duplicates (check the subset parameter)\n",
        "df = df.drop_duplicates(subset=['text','keyword'], keep='first') \n",
        "\n",
        "#Tokenization function test\n",
        "print(spa_tok(\"RT @meljomur: you know there's something seriously puts a climate disaster that wll hardly blabla!!! #fdf\"))\n",
        "\n",
        "#To improve performance : drop unused columns ('id' for now)\n",
        "df = df.drop(columns=['id'])\n",
        "df"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['meljomur', 'know', 'seriously', 'climate', 'disaster', 'wll', 'hardly', 'blabla', 'fdf']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>destroyed</td>\n",
              "      <td>USA</td>\n",
              "      <td>Black Eye 9: A space battle occurred at Star O...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bioterror</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#world FedEx no longer to transport bioterror ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>windstorm</td>\n",
              "      <td>Palm Beach County, FL</td>\n",
              "      <td>Reality Training: Train falls off elevated tra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hazardous</td>\n",
              "      <td>USA</td>\n",
              "      <td>#Taiwan Grace: expect that large rocks trees m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hostage</td>\n",
              "      <td>Australia</td>\n",
              "      <td>New ISIS Video: ISIS Threatens to Behead Croat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6466</th>\n",
              "      <td>earthquake</td>\n",
              "      <td>ARGENTINA</td>\n",
              "      <td>#Earthquake #Sismo M 1.9 - 15km E of Anchorage...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6467</th>\n",
              "      <td>derail</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@EmiiliexIrwin Totally agree.She is 23 and kno...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6468</th>\n",
              "      <td>trapped</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hollywood Movie About Trapped Miners Released ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6469</th>\n",
              "      <td>weapons</td>\n",
              "      <td>Beirut/Toronto</td>\n",
              "      <td>Friendly reminder that the only country to eve...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6470</th>\n",
              "      <td>buildings%20on%20fire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Buildings are on fire and they have time for a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6403 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    keyword  ... target\n",
              "0                 destroyed  ...      0\n",
              "1                 bioterror  ...      0\n",
              "2                 windstorm  ...      1\n",
              "3                 hazardous  ...      1\n",
              "4                   hostage  ...      1\n",
              "...                     ...  ...    ...\n",
              "6466             earthquake  ...      1\n",
              "6467                 derail  ...      0\n",
              "6468                trapped  ...      1\n",
              "6469                weapons  ...      1\n",
              "6470  buildings%20on%20fire  ...      1\n",
              "\n",
              "[6403 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfhLGYPXRZZe"
      },
      "source": [
        "# 3: Train a model\n",
        "###Basic : \n",
        "- split train/test (80/20)\n",
        "- define TF-IDF vectorizer\n",
        "- define classifier\n",
        "- fit model on training set\n",
        "- first evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qwd6D4XRMYx",
        "outputId": "5872e6df-d514-4936-c917-4c3e22194a6c"
      },
      "source": [
        "X = df['text']\n",
        "y = df['target']\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=59)\n",
        "\n",
        "X_train\n",
        "\n",
        "# Define vectorizer\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), tokenizer=spa_tok)\n",
        "\n",
        "# Define classifier\n",
        "classifier = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=72)\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "nFeat = 0\n",
        "for i in tfidf.get_feature_names():\n",
        "  nFeat += 1\n",
        "print(\"number of features created by the TF-IDF vector :\",str(nFeat))\n",
        "\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "#first evaluation\n",
        "print(f\"ACCURACY SCORE test:\\n{accuracy_score(y_test, y_pred):.3f}\")\n",
        "\n",
        "print(f\"ACCURACY SCORE train:\\n{accuracy_score(y_train, pipe.predict(X_train)):.3f}\")\n",
        "\n",
        "print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_pred)}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of features created by the TF-IDF vector : 2229\n",
            "ACCURACY SCORE train:\n",
            "0.855\n",
            "CONFUSION MATRIX:\n",
            "[[633  83]\n",
            " [183 382]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcPYVvwvVOEJ"
      },
      "source": [
        "# 4: First submission\n",
        "###Basic : \n",
        "- mount the drive in order to save the csv with submission values\n",
        "- split train/test (80/20)\n",
        "- define TF-IDF vectorizer\n",
        "- define classifier\n",
        "- fit model on training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXtrrjWUUGIA",
        "outputId": "2a67b6ea-5de2-4459-e71d-55e75b19e334"
      },
      "source": [
        "#Mount a google drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('drive')\n",
        "\n",
        "\n",
        "#To improve performance : drop unused columns ('id' for now)\n",
        "test_data = df_test['text']\n",
        "\n",
        "\n",
        "# Get & print the number of features generated by the TF-IDF vector\n",
        "nFeat = 0\n",
        "for i in tfidf.get_feature_names():\n",
        "  nFeat += 1\n",
        "print(\"number of features created by the TF-IDF vector :\",str(nFeat))\n",
        "\n",
        "test_pred = pipe.predict(test_data)\n",
        "print(type(test_pred))\n",
        "print(test_pred)\n",
        "\n",
        "#first evaluation\n",
        "print(f\"ACCURACY SCORE test:\\n{accuracy_score(y_test, y_pred):.3f}\")\n",
        "\n",
        "print(f\"ACCURACY SCORE train:\\n{accuracy_score(y_train, pipe.predict(X_train)):.3f}\")\n",
        "\n",
        "print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_pred)}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n",
            "number of features created by the TF-IDF vector : 2229\n",
            "<class 'numpy.ndarray'>\n",
            "[0 0 1 ... 1 0 1]\n",
            "ACCURACY SCORE test:\n",
            "0.792\n",
            "ACCURACY SCORE train:\n",
            "0.855\n",
            "CONFUSION MATRIX:\n",
            "[[633  83]\n",
            " [183 382]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgCtCklMbyMt"
      },
      "source": [
        "#Handle the submission file\n",
        "submission_file = pd.DataFrame(test_pred,columns=['target'])\n",
        "\n",
        "submission_file.to_csv('submission_one.csv', index=False)\n",
        "\n",
        "!cp submission_one.csv \"drive/My Drive/Team_Microsoft\""
      ],
      "execution_count": 49,
      "outputs": []
    }
  ]
}